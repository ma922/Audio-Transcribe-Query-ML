{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "\n",
    "Real-time Transcription: Design a system to transcribe continuous, potentially infinite audio streams in\n",
    "real-time, similar to how YouTube captions work. This task cannot be performed by breaking the audio\n",
    "into smaller files, saving to disk, or creating temporary files due to computational, memory, and\n",
    "potential disk cost. Upon ending the stream, the system should output \"stream ended\" and cease\n",
    "operation, not falling into an infinite loop.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer\n",
    "\n",
    "I use Open AI Whisper an open source speech to text model for transciption.\n",
    "\n",
    "The question was not so clear. There are two possibilities. \n",
    "One is that the audio file is provided and it is converted to text.\n",
    "The other possibility is that audio is provided in chunks in real time e.g steaming.\n",
    "Both implementations are provided below and working. I prefer the first implementation as it is more compatible is current version of open ai whisper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods 1\n",
    "# Provided audio file\n",
    "\n",
    "import whisper\n",
    "\n",
    "filename = \"input2.wav\"\n",
    "model = whisper.load_model(\"small\")\n",
    "result = model.transcribe(filename, fp16=False)\n",
    "print(result[\"text\"])\n",
    "print(\"stream ended\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In method 2 below:\n",
    "chunks are used to represnet audio in real time. \n",
    "Using mic audio was easier. But the question was more towards audio file.\n",
    "\n",
    "Note: The below implementation works. There are limitations in terms of optimization, as currently whisper does not has a clear implementation for audio as bytes (although input as ndarray is supported that is used for the impementation). Most people temporary file as input to the transcribe method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "# real time\n",
    "\n",
    "import numpy as np\n",
    "import whisper\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "samplerate, data = wavfile.read('input2.wav')\n",
    "if data.shape[1] > 0:\n",
    "    print('stero channel detected. Converting to mono.')\n",
    "    data = np.mean(data, axis=1)\n",
    "\n",
    "def generate_audio_chunks(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "        \n",
    "chunk_size = 32000\n",
    "data_chunks = [data]\n",
    "if len(data) > chunk_size: \n",
    "    split_size = (len(data) // chunk_size)\n",
    "    data_chunks = generate_audio_chunks(data, chunk_size)\n",
    "\n",
    "for chunk in data_chunks:\n",
    "    float_data = chunk.astype(np.float32, order='C') / 32768.0\n",
    "    audio = whisper.pad_or_trim(float_data)\n",
    "    \n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    options = whisper.DecodingOptions(fp16=False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    print(result.text, flush=True, end=' ')\n",
    "\n",
    "print(\"stream ended\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Evaluation Metrics: After transcribing the audio, your system should be able to evaluate its\n",
    "performance. Design and report appropriate metrics to measure the accuracy of the transcription."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Using jiwer\n",
    "\n",
    "JiWER is a simple and fast python package to evaluate an automatic speech recognition system. It supports the following measures:\n",
    "\n",
    "word error rate (WER)\n",
    "match error rate (MER)\n",
    "word information lost (WIL)\n",
    "word information preserved (WIP)\n",
    "character error rate (CER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27705016ebb7b86559e2dcebe8643ee1c671962ab07497ff2b4b974dffaccfbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
